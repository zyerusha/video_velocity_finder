{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy.core.numeric import True_\n",
    "from numpy.lib.arraysetops import unique\n",
    "import pandas as pd\n",
    "# import glob\n",
    "import os\n",
    "from pandas import json_normalize\n",
    "from os import getcwd, path\n",
    "from yaml import SafeLoader, load\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "from video_utils_virat import VideoUtils\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# setup\n",
    "dataset_dir_path = './datasets/VIRAT/'\n",
    "image_ext = '.jpg'\n",
    "video_max_frames = 2000\n",
    "\n",
    "#video\n",
    "video_src_path = dataset_dir_path + 'Videos/Ground/'\n",
    "video_ext = '.mp4'\n",
    "video_name = 'VIRAT_S_000203_06_001206_001266'\n",
    "video_name_orig = video_name + video_ext\n",
    "video_dest_path = './' + video_name + '/'\n",
    "video_name_new = 'annotated_' + video_name + '.avi'#video_ext\n",
    "\n",
    "# annotations\n",
    "annotations_path = dataset_dir_path + 'viratannotations-master/train/'\n",
    "ann_activities_file = annotations_path + video_name + '.activities.yml'\n",
    "ann_geom_file = annotations_path + video_name + '.geom.yml'\n",
    "ann_regions_file = annotations_path + video_name + '.regions.yml'\n",
    "ann_types_file = annotations_path + video_name + '.types.yml'\n",
    "saved_csv = video_dest_path + 'df_bbox.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory to store new video\n",
    "if not os.path.exists(video_dest_path):\n",
    "    shutil.rmtree(video_dest_path)\n",
    "    os.makedirs(video_dest_path)\n",
    "\n",
    "if not os.path.exists(saved_csv):\n",
    "    with open(ann_types_file) as yaml_file:\n",
    "        yaml_contents = load(yaml_file, Loader=SafeLoader)\n",
    "    yaml_df = json_normalize(yaml_contents)\n",
    "    yaml_df\n",
    "    for col in yaml_df.columns:\n",
    "        type_name = col.split('.')[-1]\n",
    "        if not (type_name == 'id1'):\n",
    "            yaml_df.loc[yaml_df[col] == 1, col] = type_name\n",
    "    \n",
    "    yaml_df = yaml_df[yaml_df['types.id1'].notna()].reset_index().dropna(axis=1, how='all')  \n",
    "    type_df = yaml_df.ffill(axis=1).iloc[:,-1].to_frame(name='type')\n",
    "    type_df.insert(0, \"id\", yaml_df['types.id1'])\n",
    "    type_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating annotations dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading annotations...\n"
     ]
    }
   ],
   "source": [
    "# using annotations:\n",
    "print(\"Loading annotations...\")\n",
    "def add_category_type(row):\n",
    "  id = row['object id']\n",
    "  val = type_df.loc[type_df['id'] == id, 'Category'].iloc[0]\n",
    "  return val\n",
    "\n",
    "\n",
    "if os.path.exists(saved_csv):\n",
    "  df_bbox = pd.read_csv(saved_csv)\n",
    "  df_bbox.drop(['Unnamed: 0'], axis=1)\n",
    "else:\n",
    "  with open(ann_geom_file) as yaml_file:\n",
    "      yaml_contents = load(yaml_file, Loader=SafeLoader)\n",
    "  yaml_df = json_normalize(yaml_contents)\n",
    "\n",
    "  df_bbox = yaml_df[['geom.id1','geom.ts0','geom.ts1','geom.g0']].dropna().reset_index()\n",
    "  df_bbox.rename(columns={'geom.id1': 'object id', 'geom.ts0': 'frame_id','geom.ts1': 'time_sec', 'geom.g0': 'bbox'}, inplace=True)\n",
    "  df_bbox['bbox'] = df_bbox['bbox'].str.split()\n",
    "  df_tmp = pd.DataFrame(df_bbox['bbox'].to_list(), columns = ['bb_Left', 'bb_Top', 'bb_Right', 'bb_Bottom'])\n",
    "  df_bbox = pd.concat([df_bbox, df_tmp], axis=1).drop(columns=['bbox'])\n",
    "\n",
    "  df_bbox['Category'] = df_bbox.apply(lambda row: add_category_type(row), axis=1)    \n",
    "  df_bbox.to_csv(saved_csv)\n",
    "  df_bbox.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddAllFrameAnnotations(img, df_ann, box_thickness):\n",
    "    for j in range(len(df_ann)):\n",
    "        bb_top = df_ann.iloc[j]['bb_Top']\n",
    "        bb_left = df_ann.iloc[j]['bb_Left']\n",
    "        bb_bottom = df_ann.iloc[j]['bb_Bottom']\n",
    "        bb_right = df_ann.iloc[j]['bb_Right']\n",
    "        category = df_ann.iloc[j]['Category']\n",
    "        img = vUtils.AddSingleAnnotation(img, bb_top, bb_left, bb_bottom, bb_right, category, box_thickness)\n",
    "        # img = vUtils.AddSingleAnnotation(img, df_ann.iloc[j].to_dict(), box_thickness)\n",
    "    return img\n",
    "\n",
    "\n",
    "def AnnotateVideo(output_dir, orig_v_full_path, new_v_filename, df_ann, start_time = 0, duration = []):\n",
    "    # Open original video\n",
    "    vidcap = cv2.VideoCapture(orig_v_full_path)\n",
    "    fps = vidcap.get(5) #CV_CAP_PROP_FPS = Frame rate.\n",
    "    total_frames = vidcap.get(7) # CV_CAP_PROP_FRAME_COUNT = Number of frames in the video file.\n",
    "    print(f'Total frames in video: {total_frames} @ {fps} frames/sec')\n",
    "\n",
    "    count = int(start_time * fps)\n",
    "    if(bool(duration)):\n",
    "        end_count = int((duration + start_time) * fps)\n",
    "    else:\n",
    "        end_count = total_frames - count\n",
    "        print('running full video')\n",
    "\n",
    "\n",
    "    vidcap.set(1, count) #setting CV_CAP_PROP_POS_FRAMES at count \n",
    "\n",
    "    images = []\n",
    "    img_array = np.array(images)\n",
    "\n",
    "\n",
    "\n",
    "    # # Create directory to store new video\n",
    "    # if os.path.exists(output_dir):\n",
    "    #     shutil.rmtree(output_dir)\n",
    "    # os.makedirs(output_dir)\n",
    "\n",
    "    while (True):\n",
    "        success, img = vidcap.read()\n",
    "        if(success):\n",
    "\n",
    "            # Creating a new image name\n",
    "            tmp_img_name = output_dir + \"frame%d.jpg\" % count\n",
    "            # Added new image to array of images that will construct the final video\n",
    "            img_array = np.append(img_array, tmp_img_name)\n",
    "\n",
    "            if((count % 25) == 0):\n",
    "                # print(f'Created frame id {count}, {count/fps} sec in video')\n",
    "                print(\"Created frame id %2d, %5.2f sec in video\" % (count, count/fps))\n",
    "\n",
    "\n",
    "            # All bounding box info for this frame\n",
    "            # Add all annotations to the frame\n",
    "            df_img = df_bbox[df_ann['frame_id']==count]\n",
    "            img = AddAllFrameAnnotations(img, df_img, 2)\n",
    "\n",
    "            # save the image with all its annotations\n",
    "            cv2.imwrite(tmp_img_name, img)\n",
    "        \n",
    "            count += 1\n",
    "            \n",
    "            if(count > end_count):\n",
    "                break\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    vidcap.release()  # done with original video\n",
    "\n",
    "    full_filename = output_dir + new_v_filename\n",
    "    if os.path.exists(full_filename):\n",
    "        os.remove(full_filename)\n",
    "\n",
    "    vUtils.CreateVideo(img_array, fps, full_filename)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_utils_virat import VideoUtils\n",
    "from video_utils_virat import DirectoryUtils\n",
    "# vUtils = VideoUtils(categoriesDict) \n",
    "types_lst = df_bbox['Category'].unique()\n",
    "types_dict = {}\n",
    "for i in range(len(types_lst)):\n",
    "  types_dict[types_lst[i]] = i\n",
    "\n",
    "vUtils = VideoUtils(types_dict) \n",
    "drUtils = DirectoryUtils()\n",
    "\n",
    "start_time = 0\n",
    "AnnotateVideo(video_dest_path, video_src_path + video_name_orig, video_name_new, df_bbox, start_time,1)\n",
    "\n",
    "drUtils.ClearFileType(video_dest_path,\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bb_data = df_bbox['bbox'].to_numpy()\n",
    "# count = 0\n",
    "# max_ann = 0\n",
    "# ann_cnt = 0\n",
    "# df_center = pd.DataFrame([])\n",
    "# df2  = pd.DataFrame([])\n",
    "# frame_cnt = len(bb_data)\n",
    "# for i in range(frame_cnt):\n",
    "#   ann_cnt = len(bb_data[i])\n",
    "#   lst_x = np.array([])\n",
    "#   lst_y = np.array([])\n",
    "\n",
    "#   for j in range(ann_cnt):\n",
    "#     bbox = bb_data[i][j]\n",
    "#     top = bbox['top']\n",
    "#     left = bbox['left']\n",
    "#     height = bbox['height']\n",
    "#     width = bbox['width']\n",
    "#     categories = bbox['class']\n",
    "#     bottom = top + height\n",
    "#     right = left + width\n",
    "#     center_x = int(left + width/2)\n",
    "#     center_y = int(top + height/2)\n",
    "#     center = (center_x, center_y)\n",
    "\n",
    "#     lst_x = np.append(lst_x, center_x)\n",
    "#     lst_y = np.append(lst_y, center_y)\n",
    "#     count += 1\n",
    "#     max_ann = max(max_ann, ann_cnt)\n",
    "\n",
    "#   lst_tuple = list(zip(lst_x,lst_y))\n",
    "#   print(count, ann_cnt, max_ann, lst_tuple)\n",
    "#   #   df2[i] = bbox\n",
    "#   # df_center = df_center.append(df2, ignore_index = True)\n",
    "# # print(i, df_center)\n",
    "\n",
    "# # velociy_pix [pixel/frame]\n",
    "# # frameRate   [frame/sec]\n",
    "# # scale       [m/pixel]\n",
    "# # velocity = velociy_pix * frameRate * scale; #   [m/sec] = [pixel/frame] * [frame/sec] * [m/pixel]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datashader as ds\n",
    "# import pandas as pd\n",
    "# import colorcet\n",
    "# # df  = pd.read_csv('census.csv')\n",
    "# cvs = ds.Canvas(plot_width=850, plot_height=500)\n",
    "# agg = cvs.points(df_json, 'longitude', 'latitude')\n",
    "# img = ds.tf.shade(agg, cmap=colorcet.fire, how='log')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
