{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from numpy.core.numeric import True_\n",
    "from numpy.lib.arraysetops import unique\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "make_video = False\n",
    "dataset_dir_path = './datasets/au-air/'\n",
    "save_path = './tmp/'\n",
    "annotations_path = dataset_dir_path + 'auair2019annotations/'\n",
    "image_path = dataset_dir_path + 'auair2019data/images/'\n",
    "annotations_file = annotations_path + 'annotations.json'\n",
    "video_max_frames = 2000\n",
    "\n",
    "video_ext = '.avi'\n",
    "image_ext = '.jpg'\n",
    "image_files = image_path + '*' + image_ext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def AddDateTime(names):\n",
    "#     s = pd.Series(names.str.split('_'))\n",
    "#     df_tmp = pd.DataFrame(s.tolist(), columns=['head', 'time', 'x', 'id.jpg'])\n",
    "#     s = pd.Series(df_tmp['id.jpg'].str.split('.'))\n",
    "#     df_tmp2 = pd.DataFrame(s.tolist(), columns=['id', 'jpg'])\n",
    "#     df_full['time'] = df_tmp['time']\n",
    "#     df_full['id'] = df_tmp2['id']\n",
    "#     df_full.set_index('image_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating annotations dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using annotations:\n",
    "print(\"Loading annotations...\")\n",
    "data = json.load((open(annotations_file)))\n",
    "df_json = pd.json_normalize(data, 'annotations').sort_values(by=['image_name','time.ms'])\n",
    "# df_bbox = pd.json_normalize(\n",
    "#     data, ['annotations', 'bbox'])\n",
    "# print()\n",
    "# # print(data.keys())\n",
    "categoriesDict = data['categories']\n",
    "# print(len(df_json), len(df_bbox))\n",
    "# print(df_bbox)\n",
    "print(\n",
    "    f'Number for annotation duplicates is {df_json.image_name.duplicated().sum()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Image Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# df_json_date = df_json[df_json['image_name'].str.contains(search_date)]\n",
    "\n",
    "# using images:\n",
    "print(\"Finding image names...\")\n",
    "files = np.array(glob.glob(image_files))\n",
    "df_imgs = pd.concat([pd.DataFrame([os.path.basename(file)], columns=['image_name']) for file in files],\n",
    "                    ignore_index=True)\n",
    "df_imgs['full_path'] = files\n",
    "s = pd.Series(df_imgs['image_name'].str.split('_'))\n",
    "df_tmp = pd.DataFrame(s.tolist(), columns=['head', 'short_name', 'x', 'id.jpg'])\n",
    "s = pd.Series(df_tmp['id.jpg'].str.split('.'))\n",
    "df_tmp2 = pd.DataFrame(s.tolist(), columns=['id', 'jpg'])\n",
    "df_imgs['short_name'] = df_tmp['short_name']\n",
    "df_imgs['id'] = df_tmp2['id']\n",
    "df_imgs.set_index('image_name')\n",
    "print(\n",
    "    f'Number for image duplicates is {df_imgs.image_name.duplicated().sum()}')\n",
    "\n",
    "# df_imgs = df_imgs.sort_values(by=['time', 'id']).drop_duplicates(\n",
    "#     subset=['time', 'id'])\n",
    "# year = df_json['time.year']\n",
    "# month = df_json['time.month']\n",
    "# day = df_json['time.day']\n",
    "# min = df_json['time.min']\n",
    "# sec = df_json['time.sec']\n",
    "# msec = df_json['time.ms']\n",
    "# print(year.values)\n",
    "# df_json['datetime'] = pd.Timestamp(\n",
    "#     str(year.values) + '-' + str(month.values) + '-' + str(day.values))\n",
    "# # 'time.year', 'time.month', 'time.day', 'time.hour', 'time.min', 'time.sec')\n",
    "\n",
    "# print(df_json['datetime'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.merge(df_json, df_imgs, how='inner', on='image_name')\n",
    "df_grp = df_full.groupby(\n",
    "    by=['time.year', 'time.month', 'time.day', 'time.hour', 'time.min', 'time.sec'])\n",
    "print(\"Date grouping: /n\")\n",
    "print(df_grp.size())\n",
    "\n",
    "\n",
    "plt.hist(df_full['short_name'], bins=8)\n",
    "plt.xticks(rotation = 90) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding number of recordings based on date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_dates = unique(df_full['short_name'])\n",
    "recording_cnt = len(unique_dates)\n",
    "print(f\"There are {recording_cnt} video recordings:\")\n",
    "print(unique_dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a video (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_utils import VideoUtils\n",
    "\n",
    "vu = VideoUtils()\n",
    "\n",
    "# Creates the video\n",
    "make_video = False\n",
    "\n",
    "\n",
    "# do for loop here on date\n",
    "cnt = recording_cnt\n",
    "for i in range(0, cnt):\n",
    "    search_date = unique_dates[i]\n",
    "    print('####### START #########')\n",
    "    print(f'Video # {i + 1} / {cnt}')\n",
    "    print(f'Selecting date: {search_date}')\n",
    "    df_recording = df_full[df_full['image_name'].str.contains(search_date)]\n",
    "    images = pd.Series(df_recording['full_path'].values,\n",
    "                       index=df_recording['full_path'])\n",
    "\n",
    "# Calculate Frames Per Second\n",
    "    timespan_ms = df_recording['time.ms'].iloc[-1] - \\\n",
    "        df_recording['time.ms'].iloc[0]\n",
    "    timespan_sec = timespan_ms/1000\n",
    "    print(\n",
    "        f'Recording duration is {timespan_sec} sec')\n",
    "    fps = len(df_recording)/timespan_sec\n",
    "    print(f'fps: {fps}')\n",
    "\n",
    "    if(make_video):\n",
    "        video_name = 'video_' + search_date\n",
    "        if os.path.exists(video_name + video_ext):\n",
    "            os.remove(video_name + video_ext)\n",
    "        vu.CreateVideo(images, fps, video_name, video_ext, video_max_frames)\n",
    "\n",
    "    print('######## END ##########')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from video_utils import VideoUtils\n",
    "# vu = VideoUtils() \n",
    "# save_dir =  './new_video_20190829091111_2/'     \n",
    "# created_images_array = vu.SplitVideoToFrames(save_dir, 'video_20190829091111_2.avi')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct annotated video step by step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Video selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from video_utils import VideoUtils\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "# vu = VideoUtils(categoriesDict) \n",
    "\n",
    "# rec_timestamp = '20190829091111' #this should be the same as unique_dates[0]\n",
    "# recording_name_postfix = 2 #this should be the same as unique_dates[0]\n",
    "# video_ext = '.avi'\n",
    "# save_dir =  './new_video_' + rec_timestamp + '_' + str(recording_name_postfix) + '/' \n",
    "# orig_video_name =  'video_' + rec_timestamp + '_' +  str(recording_name_postfix) + video_ext\n",
    "# new_video_name =  'annotated_' + rec_timestamp + '_' +  str(recording_name_postfix) + video_ext\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.  Split video to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# created_images_array, cnt = vu.SplitVideoToFrames(save_dir, orig_video_name)\n",
    "# images = pd.Series(created_images_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Find relevent annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############\n",
    "# # create image array from reading the actual images\n",
    "# #img_array = vu.CreateImagesArray(images, len(created_images_array))\n",
    "# print(rec_timestamp)\n",
    "# # select the annotations that are only relevent to the current recording\n",
    "# frames_cnt = len(created_images_array)\n",
    "# df_recording_bbox = df_full[df_full['short_name'] == rec_timestamp][['time.ms','bbox']]\n",
    "# # remove all non relevent data\n",
    "# start_index = max((recording_name_postfix-1)*video_max_frames, 0)\n",
    "# end_index = start_index + frames_cnt\n",
    "# # print(start_index)\n",
    "# # print(df_recording_bbox)\n",
    "# df_bbox = df_recording_bbox.iloc[start_index:end_index]\n",
    "\n",
    "# # print(df_bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Add annotations to frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i_img in range(len(images)):\n",
    "#   frame_name = images[i_img]\n",
    "#   bbox_data_for_img = df_bbox['bbox'].iloc[i_img]\n",
    "#   vu.AddAllFrameAnnotations(frame_name, bbox_data_for_img, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.  Create video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate Frames Per Second\n",
    "# timespan_ms = df_bbox['time.ms'].iloc[-1] - df_bbox['time.ms'].iloc[0]\n",
    "# timespan_sec = timespan_ms/1000\n",
    "# fps = len(df_bbox)/timespan_sec\n",
    "\n",
    "# if os.path.exists(new_video_name + video_ext):\n",
    "#     os.remove(new_video_name + video_ext)\n",
    "\n",
    "# vu.CreateVideo(images, fps, new_video_name, video_max_frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cleanup, remove frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #clears all frames in folder\n",
    "# files_in_directory = os.listdir(save_dir)\n",
    "# filtered_files = [file for file in files_in_directory if file.endswith(\".jpg\")]\n",
    "# for file in filtered_files:\n",
    "# \tpath_to_file = os.path.join(save_dir, file)\n",
    "# \tos.remove(path_to_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_utils import VideoUtils\n",
    "from video_utils import DirectoryUtils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "vUtils = VideoUtils(categoriesDict) \n",
    "drUtils = DirectoryUtils()\n",
    "\n",
    "rec_timestamp = '20190905112522' #this should be the same as unique_dates[0]\n",
    "recording_name_postfix = 2 #this should be the same as unique_dates[0]\n",
    "video_ext = '.avi'\n",
    "save_dir =  './new_video_' + rec_timestamp + '_' + str(recording_name_postfix) + '/' \n",
    "orig_video_name =  'video_' + rec_timestamp + '_' +  str(recording_name_postfix) + video_ext\n",
    "new_video_name =  'annotated_' + rec_timestamp + '_' +  str(recording_name_postfix) + video_ext\n",
    "video_max_frames = 2000\n",
    "\n",
    "start_index = max((recording_name_postfix-1)*video_max_frames, 0)\n",
    "end_index = start_index + video_max_frames\n",
    "df_bbox = df_full[df_full['short_name'] == rec_timestamp][['bbox']].iloc[start_index:end_index]\n",
    "\n",
    "vUtils.AnnotateVideo(save_dir, orig_video_name, new_video_name, df_bbox['bbox'].to_numpy(), 30, 2000)\n",
    "\n",
    "drUtils.ClearFileType(save_dir,\".jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datashader as ds\n",
    "# import pandas as pd\n",
    "# import colorcet\n",
    "# # df  = pd.read_csv('census.csv')\n",
    "# cvs = ds.Canvas(plot_width=850, plot_height=500)\n",
    "# agg = cvs.points(df_json, 'longitude', 'latitude')\n",
    "# img = ds.tf.shade(agg, cmap=colorcet.fire, how='log')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
