{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MW-p089pqYd",
        "outputId": "8a2290f6-bdd8-42b1-904c-df748e8034c1"
      },
      "outputs": [],
      "source": [
        "# clone repository for deepsort with yolov4\n",
        "# forked from theAIGuysCode/yolov4-deepsort\n",
        "# !git clone https://github.com/zyerusha/yolov4-deepsort  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaWKeglDrPfc",
        "outputId": "a6e8f23d-a662-4def-ef58-9138a8825b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python==4.5.4.60 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements-gpu.txt (line 1)) (4.5.4.60)\n",
            "Requirement already satisfied: tensorflow-gpu==2.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements-gpu.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: lxml in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements-gpu.txt (line 3)) (4.6.3)\n",
            "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements-gpu.txt (line 4)) (4.62.3)\n",
            "Requirement already satisfied: absl-py in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements-gpu.txt (line 5)) (1.0.0)\n",
            "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements-gpu.txt (line 6)) (3.4.3)\n",
            "Requirement already satisfied: easydict in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements-gpu.txt (line 7)) (1.9)\n",
            "Requirement already satisfied: pillow in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements-gpu.txt (line 8)) (8.4.0)\n",
            "Requirement already satisfied: pyscreenshot in c:\\programdata\\anaconda3\\lib\\site-packages (from -r requirements-gpu.txt (line 9)) (3.0)\n",
            "Requirement already satisfied: numpy>=1.19.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from opencv-python==4.5.4.60->-r requirements-gpu.txt (line 1)) (1.20.3)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (3.19.1)\n",
            "Requirement already satisfied: gast<0.5.0,>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (12.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (0.23.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (1.12.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: tensorboard~=2.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (3.3.0)\n",
            "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (1.43.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.32.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (0.37.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->-r requirements-gpu.txt (line 4)) (0.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements-gpu.txt (line 6)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements-gpu.txt (line 6)) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements-gpu.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->-r requirements-gpu.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: entrypoint2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyscreenshot->-r requirements-gpu.txt (line 9)) (0.2.4)\n",
            "Requirement already satisfied: mss in c:\\programdata\\anaconda3\\lib\\site-packages (from pyscreenshot->-r requirements-gpu.txt (line 9)) (6.1.0)\n",
            "Requirement already satisfied: EasyProcess in c:\\programdata\\anaconda3\\lib\\site-packages (from pyscreenshot->-r requirements-gpu.txt (line 9)) (0.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (2.26.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (1.8.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (2.3.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (3.3.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (58.0.4)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (4.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (0.4.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (3.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (1.26.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (2.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow-gpu==2.7.0->-r requirements-gpu.txt (line 2)) (3.1.1)\n"
          ]
        }
      ],
      "source": [
        "# uncomment below line ONLY if needed\n",
        "!pip install -r requirements-gpu.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../yolo/weights/yolov4.weights'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20268/3247319906.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0msrc_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../yolo/weights/yolov4.weights'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtgt_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./yolov4.weights'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mcopy2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopy2\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m         \u001b[0mdst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 443\u001b[1;33m     \u001b[0mcopyfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    444\u001b[0m     \u001b[0mcopystat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    263\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m                 \u001b[1;31m# macOS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../yolo/weights/yolov4.weights'"
          ]
        }
      ],
      "source": [
        "from shutil import copy2\n",
        "src_dir = '../yolo/weights/yolov4.weights'\n",
        "tgt_dir = './yolov4.weights'\n",
        "copy2(src_dir, tgt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twV0dpNIw4lQ",
        "outputId": "106961a9-dbbd-4794-eddc-f584fbf5ab1a"
      },
      "outputs": [],
      "source": [
        "# Convert darknet weights to tensorflow model\n",
        "%cd tensorflow_yolov4_tflite/\n",
        "!python save_model.py --model yolov4 --weights ../yolov4.weights --output ../checkpoints/yolov4\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "def CopyNeededFolders(folder_name, src_dir, target_dir = '.'):\n",
        "    tgt_name = os.path.join(target_dir, folder_name)\n",
        "    src_name = os.path.join(src_dir, folder_name)\n",
        "    if os.path.isdir(tgt_name): \n",
        "        shutil.rmtree(tgt_name) \n",
        "    shutil.copytree(src_name,tgt_name)\n",
        "    print(f'Copied folder {src_name} --> {tgt_name}')\n",
        "\n",
        "CopyNeededFolders('data', './tensorflow_yolov4_tflite', '.') \n",
        "CopyNeededFolders('core', './tensorflow_yolov4_tflite', '.') \n",
        "CopyNeededFolders('model_data', '../yolov4-deepsort', '.') \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# setup\n",
        "dataset_dir_path = '../datasets/VIRAT/'\n",
        "image_ext = '.jpg'\n",
        "video_max_frames = 2000\n",
        "\n",
        "#video\n",
        "video_ext = '.mp4'\n",
        "video_name = 'VIRAT_S_050000_07_001014_001126'\n",
        "video_name_orig = video_name + video_ext\n",
        "video_dest_path = './processed/' +  video_name + '/'\n",
        "video_src_path = dataset_dir_path + 'Videos/Ground/'\n",
        "\n",
        "using_yml = True\n",
        "\n",
        "# annotations\n",
        "saved_csv = video_dest_path + 'df_bbox.csv'\n",
        "\n",
        "\n",
        "yml_video_name = 'gt'\n",
        "yolo_video_name = 'yolo'\n",
        "\n",
        "# annotations_path = dataset_dir_path + 'viratannotations/train/' + video_name +'/'\n",
        "annotations_path = dataset_dir_path + 'viratannotations/validate/' + video_name +'/'\n",
        "ann_activities_file = annotations_path + video_name + '.activities.yml'\n",
        "ann_geom_file = annotations_path + video_name + '.geom.yml'\n",
        "ann_regions_file = annotations_path + video_name + '.regions.yml'\n",
        "ann_types_file = annotations_path + video_name + '.types.yml'\n",
        "\n",
        "\n",
        "src_video = os.path.join(video_src_path, video_name_orig)\n",
        "gt_video_name = yml_video_name + '_' # + '.mp4'#video_ext\n",
        "yolo_video_name = yolo_video_name + '_'# + '.mp4'#video_ext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create directory to store new video\n",
        "if not os.path.exists(video_dest_path):\n",
        "    os.makedirs(video_dest_path)\n",
        "\n",
        "if not os.path.exists(saved_csv):\n",
        "    with open(ann_types_file) as yaml_file:\n",
        "        yaml_contents = load(yaml_file, Loader=SafeLoader)\n",
        "    yaml_df = json_normalize(yaml_contents)\n",
        "    yaml_df\n",
        "    for col in yaml_df.columns:\n",
        "        type_name = col.split('.')[-1]\n",
        "        if not (type_name == 'id1'):\n",
        "            yaml_df.loc[yaml_df[col] == 1, col] = type_name\n",
        "    \n",
        "    yaml_df = yaml_df[yaml_df['types.id1'].notna()].reset_index().dropna(axis=1, how='all')  \n",
        "    type_df = yaml_df.ffill(axis=1).iloc[:,-1].to_frame(name='category')\n",
        "    type_df.insert(0, \"id\", yaml_df['types.id1'])\n",
        "    type_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# using annotations:\n",
        "print(\"Loading annotations...\")\n",
        "def add_category_type(row):\n",
        "  id = row['object_id']\n",
        "  val = type_df.loc[type_df['id'] == id, 'category'].iloc[0]\n",
        "  return val\n",
        "\n",
        "\n",
        "if os.path.exists(saved_csv):\n",
        "  df_bbox = pd.read_csv(saved_csv)\n",
        "else:\n",
        "  with open(ann_geom_file) as yaml_file:\n",
        "      yaml_contents = load(yaml_file, Loader=SafeLoader)\n",
        "  yaml_df = json_normalize(yaml_contents)\n",
        "\n",
        "  df_bbox = yaml_df[['geom.id1','geom.ts0','geom.ts1','geom.g0']].dropna().reset_index()\n",
        "  df_bbox.rename(columns={'geom.id1': 'object_id', 'geom.ts0': 'frame_id','geom.ts1': 'time_sec', 'geom.g0': 'bbox'}, inplace=True)\n",
        "  df_bbox['bbox'] = df_bbox['bbox'].str.split()\n",
        "  df_tmp = pd.DataFrame(df_bbox['bbox'].to_list(), columns = ['bb_left', 'bb_top', 'bb_right', 'bb_bottom'])\n",
        "  df_bbox = pd.concat([df_bbox, df_tmp], axis=1).drop(columns=['bbox'])\n",
        "\n",
        "  df_bbox['category'] = df_bbox.apply(lambda row: add_category_type(row), axis=1) \n",
        "  df_bbox.drop(columns=['index'], axis=1, inplace=True)\n",
        "  # df_bbox.set_index['index'] \n",
        "  df_bbox.to_csv(saved_csv, index = False)\n",
        "    \n",
        "\n",
        "df_bbox.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# from utils.velocity_utils import VelocityUtils\n",
        "# velUtils = VelocityUtils() \n",
        "\n",
        "# vidcap = cv2.VideoCapture(src_video)\n",
        "# fps = 30\n",
        "# scale = 1/15\n",
        "# if vidcap.isOpened():\n",
        "#     fps = vidcap.get(cv2.CAP_PROP_FPS)  \n",
        "#     print(fps)\n",
        "\n",
        "# df_bbox = velUtils.add_vel_to_df(df_bbox, fps, scale)\n",
        "\n",
        "# df_bbox.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "from utils.yolo_utils import YoloUtils\n",
        "from utils.video_utils import VideoUtils\n",
        "from utils.folder_utils import FolderUtils\n",
        "from utils.deepsort_yolo import DeepsortYolo\n",
        "yUtils = YoloUtils()\n",
        "vUtils = VideoUtils() \n",
        "deepsortYolo  = DeepsortYolo()\n",
        "\n",
        "# yolo_weight_file = \"../yolo/weights/yolov3.weights\"\n",
        "# yolo_cfg_file = \"../yolo/darknet/cfg/yolov3.cfg\"\n",
        "yolo_names_file = \"../yolo/darknet/data/coco.names\"\n",
        "# yolo_weight_file = \"yolov4.weights\"\n",
        "# yolo_cfg_file = \"../yolo/darknet/cfg/yolov3.cfg\"\n",
        "# yolo_names_file = \"../yolo/darknet/data/coco.names\"\n",
        "start_time = 0\n",
        "video_duration=10#None\n",
        "video_in = cv2.VideoCapture(src_video)\n",
        "if video_in.isOpened():\n",
        "    fps, total_frames, frame_size = vUtils.GetVideoData(video_in)\n",
        "    start_count, end_count = vUtils.GetStartEndCount(fps, total_frames, start_time, video_duration)\n",
        "    video_duration = int(end_count / fps)\n",
        "    video_in.release()\n",
        "\n",
        "\n",
        "yolo_filename = os.path.join(video_dest_path, VideoUtils.AddTimestampToName(yolo_video_name, start_time, video_duration))\n",
        "gt_filename = os.path.join(video_dest_path, VideoUtils.AddTimestampToName(gt_video_name, start_time, video_duration))\n",
        "\n",
        "tracker_file_csv = yolo_filename + '.csv'\n",
        "tracker_file_mp4 = yolo_filename + '.mp4'\n",
        "gt_file_mp4 = gt_filename + '.mp4'\n",
        "if not os.path.exists(tracker_file_csv):\n",
        "    tracker_video_out, trk_bbox = deepsortYolo.ProcessVideo(\"./checkpoints/yolov4\", yolo_names_file, src_video, video_dest_path, tracker_file_mp4, start_time_sec=start_time, duration_sec=video_duration, save_images=False)\n",
        "    trk_bbox.to_csv(tracker_file_csv, index=False)\n",
        "\n",
        "    if os.path.exists(gt_filename):\n",
        "        df_bbox_filtered = df_bbox[df_bbox['category'] == 'Vehicle']\n",
        "        gt_video_out, bbox_gt = vUtils.AnnotateVideo(video_dest_path, tracker_video_out, gt_file_mp4, df_bbox_filtered, start_time, video_duration)\n",
        "    \n",
        "\n",
        "\n",
        "# \n",
        "# yolo_video_out, trk_bbox = deepsortYolo.ProcessVideo(\"./checkpoints/yolov4\", yolo_names_file, src_video, video_dest_path, yolo_filename + '.mp4', start_time_sec=start_time, duration_sec=video_duration, save_images=False)\n",
        "# trk_bbox.to_csv(os.path.join(video_dest_path,'image_data.csv'), index=False)\n",
        "trk_bbox = pd.read_csv(tracker_file_csv)\n",
        "# gt_video_out, bbox_gt = vUtils.AnnotateVideo(video_dest_path, yolo_video_out, gt_filename + '.mp4', df_bbox_vehicle, start_time, video_duration)\n",
        "trk_bbox"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from utils.video_utils import VideoUtils\n",
        "from utils.velocity_utils import VelocityUtils\n",
        "from utils.filtering_utils import Filters\n",
        "vUtils = VideoUtils() \n",
        "velUtils = VelocityUtils()\n",
        "\n",
        "\n",
        "df = pd.DataFrame(data=trk_bbox)\n",
        "df.head(50)\n",
        "  \n",
        "scale = 1/15\n",
        "\n",
        "df_person = df[(df['object_id'] == 4)]\n",
        "human_height_avg = 1.75\n",
        "human_pixel_height =(df_person['bb_bottom'].mean() - df_person['bb_top'].mean()) \n",
        "scale = human_height_avg / human_pixel_height\n",
        "print(f'human pixel high: {human_pixel_height}, avg human height: {human_height_avg}, scale: {scale}')\n",
        "\n",
        "\n",
        "df = df.reset_index()\n",
        "df = df.drop(columns = ['index'])\n",
        "for id in df['object_id'].unique():\n",
        "  # this adds velocity to the dataframe\n",
        "  df = velUtils.AddVelocity(df, id, fps, scale, ['bb_left', 'bb_top', 'bb_right', 'bb_bottom'])\n",
        "  # df = velUtils.FilterVelocity(df, id, fps)\n",
        "\n",
        "# df.to_csv(os.path.join(video_dest_path,'image_data_vel.csv'), index=False)\n",
        "\n",
        "# df['vel'][df['vel'] < 1] = 0\n",
        "\n",
        "df_test = pd.DataFrame(df[(df['object_id'] == 13)])\n",
        "\n",
        "# df_test['vel_filt'] =  Filters.ButterLowpass(df_test['vel'], 2, fps, 1)\n",
        "\n",
        "\n",
        "df_test.head(50)\n",
        "\n",
        "\n",
        "# "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# df['vel_filt'] =  ButterLowpassFilter(df['vel'], float(1/fps), fps, 1)\n",
        "# tmp= pd.DataFrame([])\n",
        "# tmp['x'] = df[(df['object_id'] == 5)]['Frame']\n",
        "# tmp['y1'] = df[(df['object_id'] == 5)]['vel']\n",
        "# tmp['y2'] = df[(df['object_id'] == 5)]['vel_filt']\n",
        "# tmp.head()\n",
        "# plt.plot(tmp['x'],tmp['y1'], tmp['x'],tmp['y2'])\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "def AddVelocityToFrame(frame, df_info):\n",
        "    for index, row in df_info.iterrows():\n",
        "        # bb_gt = row['gt bbox']\n",
        "        # txt_val = \"{vel:.2f}\".format(vel = row['vel_filt'])\n",
        "        txt_val = \"{vel:.2f}\".format(vel = row['vel'])\n",
        "        cv2.putText(frame, txt_val, (int(row['x']), int(row['y'])), cv2.FONT_HERSHEY_COMPLEX, 0.75, (0, 255, 255), 1)\n",
        "        # img = vUtils.PrintText(img, txt_val, row['x'], row['y'], -10, 10, cv2.FONT_HERSHEY_COMPLEX, 0.75, (255, 255, 255))\n",
        "    return frame\n",
        "\n",
        "\n",
        "def AddVelocityToVideo(orig_v_full_path, df):\n",
        "    if (not orig_v_full_path):\n",
        "        raise Exception(f\"File not found: {orig_v_full_path}\")\n",
        "\n",
        "    p = Path(orig_v_full_path)\n",
        "    filename = os.path.join(p.parent, \"vel_\" + p.name)\n",
        "\n",
        "    bbox_data = {}\n",
        "    # Open original video\n",
        "    video_in = cv2.VideoCapture(orig_v_full_path)\n",
        "    if video_in.isOpened():\n",
        "        fps, total_frames, frame_size = vUtils.GetVideoData(video_in)\n",
        "        count = 0\n",
        "        # setting CV_CAP_PROP_POS_FRAMES at count\n",
        "        video_in.set(cv2.CAP_PROP_POS_FRAMES, count)\n",
        "        \n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "        video_out = cv2.VideoWriter(\n",
        "            filename, fourcc, int(fps), frame_size)\n",
        "\n",
        "        i = 0\n",
        "        while (True):\n",
        "            success, frame = video_in.read()\n",
        "            if(success):\n",
        "                # height, width, layers = frame.shape\n",
        "                # image_size = (width, height)\n",
        "\n",
        "                # All bounding box info for this frame\n",
        "                # Add all annotations to the frame\n",
        "                frame = AddVelocityToFrame(frame, df[df['Frame'] == count])\n",
        "                i += 1\n",
        "                video_out.write(frame)\n",
        "                count += 1\n",
        "\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        video_in.release()  # done with original video\n",
        "        video_out.release()\n",
        "\n",
        "        print(\"Done: Created video: \" + filename)\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "# yolo_video_out = os.path.join(video_dest_path,'0-10_yolo_VIRAT_S_050000_07_001014_001126.mp4')\n",
        "\n",
        "AddVelocityToVideo(tracker_file_mp4, df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from utils.bbox_utils import Bbox\n",
        "import pandas as pd\n",
        "\n",
        "def GetMaxCorrelation(bb_gt, pred_bboxes, frame):\n",
        "    max_iou = 0.0\n",
        "    max_info = [frame, bb_gt, bb_gt, max_iou]\n",
        "    found = False\n",
        "\n",
        "    for bb_pred in pred_bboxes:\n",
        "        gt = Bbox(bb_gt[0],bb_gt[1],bb_gt[2],bb_gt[3])\n",
        "        pred = Bbox(bb_pred[0],bb_pred[1],bb_pred[2],bb_pred[3])\n",
        "        iou = gt.IOU(pred)\n",
        "\n",
        "        if (max_iou < iou) & (0.5 < iou):\n",
        "            found = True\n",
        "            max_iou = iou\n",
        "            max_info = [frame, bb_gt, bb_pred, iou]\n",
        "\n",
        "    return found, max_info\n",
        "\n",
        "df = pd.DataFrame(columns=['frame idx', 'gt bbox', 'pred bbox', 'iou'])\n",
        "print(f'# of frames in video: {len(bbox_gt)}')\n",
        "# for i_frame in range(1):#range(len(bbox_gt)): #scan all frames in video\n",
        "for i_frame in range(len(bbox_gt)): #scan all frames in video\n",
        "    data = []\n",
        "    for bb_gt in bbox_gt[i_frame]:\n",
        "        found, info = GetMaxCorrelation(bb_gt, bbox_yolo[i_frame], i_frame)\n",
        "        if(found):\n",
        "            data.append(info)\n",
        "    \n",
        "    df_frame = pd.DataFrame(data, columns=['frame idx', 'gt bbox', 'pred bbox', 'iou'])\n",
        "    df = pd.concat([df, df_frame], ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "mPA = df['iou'].sum()/len(df)\n",
        "print(mPA)\n",
        "df.head(30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# add IOU to video\n",
        "from video_utils_virat import VideoUtils\n",
        "vUtils = VideoUtils() \n",
        "\n",
        "gt_video_out\n",
        "\n",
        "def AddIouToFrame(img, df_info):\n",
        "    for index, row in df_info.iterrows():\n",
        "        bb_gt = row['gt bbox']\n",
        "        txt_val = \"{iou:.4f}\".format(iou = row['iou'])\n",
        "        bb = Bbox(bb_gt[0],bb_gt[1],bb_gt[2],bb_gt[3])\n",
        "        img = vUtils.PrintText(img, txt_val, bb.center_x, bb.center_y, -10, 10, cv2.FONT_HERSHEY_COMPLEX, 0.75, (255, 255, 255))\n",
        "    return img\n",
        "\n",
        "\n",
        "def AddIouToVideo(output_dir, orig_v_full_path, df_info):\n",
        "    if (not orig_v_full_path):\n",
        "        raise Exception(f\"File not found: {orig_v_full_path}\")\n",
        "\n",
        "    bbox_data = {}\n",
        "    # Open original video\n",
        "    video_in = cv2.VideoCapture(orig_v_full_path)\n",
        "    if video_in.isOpened():\n",
        "        fps, total_frames, frame_size = vUtils.GetVideoData(video_in)\n",
        "        count = 0\n",
        "        # setting CV_CAP_PROP_POS_FRAMES at count\n",
        "        video_in.set(cv2.CAP_PROP_POS_FRAMES, count)\n",
        "        full_filename = os.path.join(output_dir,'IOU.mp4')\n",
        "        if os.path.exists(full_filename):\n",
        "            os.remove(full_filename)\n",
        "\n",
        "        fourcc = cv2.VideoWriter_fourcc(*\"XVID\")\n",
        "        video_out = cv2.VideoWriter(\n",
        "            full_filename, fourcc, int(fps), frame_size)\n",
        "\n",
        "        i = 0\n",
        "        while (True):\n",
        "            success, img = video_in.read()\n",
        "            if(success):\n",
        "                height, width, layers = img.shape\n",
        "                image_size = (width, height)\n",
        "\n",
        "                # All bounding box info for this frame\n",
        "                # Add all annotations to the frame\n",
        "                df_img = df_info[df_info['frame idx'] == count]\n",
        "                img = AddIouToFrame(img, df_img)\n",
        "                i += 1\n",
        "                video_out.write(img)\n",
        "                count += 1\n",
        "\n",
        "            else:\n",
        "                break\n",
        "\n",
        "        video_in.release()  # done with original video\n",
        "        video_out.release()\n",
        "\n",
        "        print(\"Done: Created video: \" + full_filename)\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "\n",
        "AddIouToVideo(video_dest_path, gt_video_out, df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from video_utils_virat import YoloUtils\n",
        "# yUtils = YoloUtils()\n",
        "# yolo_weight_file = \"../yolo/weights/yolov3.weights\"\n",
        "# yolo_cfg_file = \"../yolo/darknet/cfg/yolov3.cfg\"\n",
        "# yolo_names_file = \"../yolo/darknet/data/coco.names\"\n",
        "# yUtils.YoloOnScreen(yolo_weight_file, yolo_cfg_file, yolo_names_file, 0,0,800,600)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "YOLOv4_DeepSort.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
